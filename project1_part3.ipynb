{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project1_part3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pierresegonne/ELEC5307_Project1/blob/master/project1_part3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t0iPF873e03",
        "colab_type": "text"
      },
      "source": [
        "# UTILS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hF87HZRn1UFF",
        "colab_type": "code",
        "outputId": "ca71ae53-c01d-4174-a9e1-b7379b843318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "# Install pytorch\n",
        "\n",
        "from os import path\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "\n",
        "accelerator = 'cu80' if path.exists('/opt/bin/nvidia-smi') else 'cpu'\n",
        "print('Accelerator: ', accelerator)\n",
        "\n",
        "print('Installing Torch') \n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-1.0.0-{platform}-linux_x86_64.whl\n",
        "# Issue with torchvision version\n",
        "!pip install torchvision==0.2.1\n",
        "import torch\n",
        "import torchvision"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accelerator:  cpu\n",
            "Installing Torch\n",
            "\u001b[K     |████████████████████████████████| 69.4MB 50.8MB/s \n",
            "\u001b[31mERROR: torchvision 0.3.0 has requirement torch>=1.1.0, but you'll have torch 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (1.16.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.2.1) (4.3.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision==0.2.1) (0.46)\n",
            "Installing collected packages: torchvision\n",
            "  Found existing installation: torchvision 0.3.0\n",
            "    Uninstalling torchvision-0.3.0:\n",
            "      Successfully uninstalled torchvision-0.3.0\n",
            "Successfully installed torchvision-0.2.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ELd4etA2pLA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ROOT_DIRECTORY = '.'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0LchfQF2ut_",
        "colab_type": "code",
        "outputId": "db6334e9-dead-4c0b-e64e-cb24a34d39c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "# Allow saving files to google drive if ran on colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "ROOT_DIRECTORY = '/content/gdrive/My Drive/Colab Notebooks/ELEC5307 Project1'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWNbVCSn3jHA",
        "colab_type": "text"
      },
      "source": [
        "# IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB0P1mOh3b8Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# useful packages\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn\n",
        "\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import SubsetRandomSampler\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import math\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import pickle\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8jTLUHsPjul",
        "colab_type": "text"
      },
      "source": [
        "# HYPERPARAMETERS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jDXwpQePmkG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LEARNING_RATE = 0.001\n",
        "BATCH_SIZE = 8\n",
        "EPOCHS = 16\n",
        "\n",
        "CROP_SIZE=24\n",
        "\n",
        "FIRST_LAYER_OUT_CHANNELS = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDeDL3wW2_dv",
        "colab_type": "text"
      },
      "source": [
        "# CODE\n",
        "\n",
        "## 1st Influence: Data Transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TavHZH483LYl",
        "colab_type": "code",
        "outputId": "f455e4bc-cf82-40d6-d581-95d524420a19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\"\"\"\n",
        "Modification of the transformations\n",
        "Choice          Parameters\n",
        "---------------------------\n",
        "Center Crop     size\n",
        "Five Crop       size\n",
        "Resize          size + interpolation\n",
        "\"\"\"\n",
        "train_transform_original = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "train_transform_centercrop = transforms.Compose(\n",
        "    [# Cropping\n",
        "     transforms.CenterCrop(CROP_SIZE),\n",
        "     transforms.Resize(32),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "def handleFiveCrops(crops):\n",
        "    # original \n",
        "    # return torch.stack([ToTensor()(crop) for crop in crops])\n",
        "    tensor_stack = []\n",
        "    for crop in crops:\n",
        "      new_tensor = transforms.Compose([\n",
        "                                       transforms.Resize(32),\n",
        "                                       transforms.ToTensor(),\n",
        "                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "                                       ])(crop)\n",
        "      tensor_stack.append(new_tensor)\n",
        "    return torch.stack(tensor_stack)\n",
        "\n",
        "def randomFromFiveCrops(crops):\n",
        "    randomIndex = random.randint(0,len(crops)-1)\n",
        "    return crops[randomIndex]\n",
        "\n",
        "train_transform_fivecrop = transforms.Compose(\n",
        "    [# Cropping\n",
        "     transforms.FiveCrop(22),\n",
        "     # transforms.Lambda(lambda crops: torch.stack([transforms.ToTensor()(crop) for crop in crops])),\n",
        "     transforms.Lambda(lambda crops: handleFiveCrops(crops)),\n",
        "     ])\n",
        "\n",
        "train_transform_modified = transforms.RandomChoice([\n",
        "    transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]),\n",
        "    transforms.Compose([\n",
        "                        transforms.FiveCrop(24), # What choice here?\n",
        "                        transforms.Lambda(lambda crops: randomFromFiveCrops(crops)),\n",
        "                        transforms.Resize(32),\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ]),                     \n",
        "  ])\n",
        "\n",
        "\n",
        "train_transform = train_transform_modified\n",
        "\n",
        "test_transform = transforms.ToTensor()\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=train_transform)\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=test_transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9VkJ98h8qrW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "7040f472-63e6-4d2b-e62f-f88dc31e71b1"
      },
      "source": [
        "def showimg(tensor):\n",
        "    tensor = tensor / 2 + 0.5     # unnormalize, because normalization is (img - 0.5)/0.5 in transforms.Normalize\n",
        "    npimg = tensor.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\n",
        "# Visualization of random training images\n",
        "dataiter = trainloader.__iter__()\n",
        "input, labels = dataiter.next()\n",
        "\n",
        "# ------\n",
        "# IF FIVE CROPS TOTAL\n",
        "# bs, ncrops, c, h, w = input.size()\n",
        "# input = input.view(-1, c, h, w) # fuse crops and bs\n",
        "# if include the five crop, how to handle the difference in shapes with at random?\n",
        "# Can just have a switch, if five crops, multiplies the bs by 5.\n",
        "# ------\n",
        "\n",
        "print(input.shape)\n",
        "# show images\n",
        "showimg(torchvision.utils.make_grid(input))\n",
        "\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 32, 32])\n",
            "  dog truck  deer  deer\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAB6CAYAAACvHqiXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJPj/GGun1xwhNUgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcOPhxwtQNJ8",
        "colab_type": "text"
      },
      "source": [
        "#### Generate the Test/Validation Split to monitor training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrK5UPiWQSXd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VALIDATION_SET_SIZE = 2000\n",
        "\n",
        "indices = np.arange(len(trainset))\n",
        "np.random.shuffle(indices) # for shuffle = True\n",
        "split = len(trainset) - VALIDATION_SET_SIZE\n",
        "RECORD_EVERY = 2000\n",
        "\n",
        "\n",
        "validation_set_size = len(indices) - split\n",
        "\n",
        "train_sampler, validation_sampler = SubsetRandomSampler(indices[:split]), SubsetRandomSampler(indices[split:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdjijQep3xS4",
        "colab_type": "text"
      },
      "source": [
        "##2nd Influence: Network Structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxNx7Rad32Ar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        # define the network layers\n",
        "\n",
        "        # nn.Conv2d(input_channel, output_channel, filter_size,\n",
        "        #     stride=stride, padding=padding)\n",
        "        # By default, padding=0, stride=1\n",
        "        # CIFAR 10 is 32*32*3\n",
        "        # Pooling Method, Kernel size, dropout and activation method shall not be experimented with.\n",
        "\n",
        "        # .,3,32,32\n",
        "        self.conv1 = nn.Conv2d(3,32,5) \n",
        "        # .,32,28,28\n",
        "        self.pool1 = nn.MaxPool2d(2,2)\n",
        "        # .,32,14,14\n",
        "        self.conv2 = nn.Conv2d(32,64,5)\n",
        "        # .,64,10,10\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "        # .,64,5,5\n",
        "        self.conv3 = nn.Conv2d(64,128,5)\n",
        "        # .,128,1,1\n",
        "        self.pool3 = nn.MaxPool2d(2,2)\n",
        "        # .,128,1,1\n",
        "\n",
        "        self.fc1 = nn.Linear(128,80)\n",
        "        self.fc2 = nn.Linear(80,64)\n",
        "        self.fc3 = nn.Linear(64,10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # define the network structure\n",
        "        x = self.pool1(F.relu(self.conv1(x)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = self.pool3(F.relu(self.conv3(x)))\n",
        "\n",
        "        # Reshape\n",
        "        x = x.view(-1,128)\n",
        "\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "cnn = CNN()\n",
        "\n",
        "# test\n",
        "# REMINDER, shape of tensor: [BS, CH, HEIGHT, WIDTH]\n",
        "TEST_INPUT = False\n",
        "if TEST_INPUT:\n",
        "  input = torch.rand((1,3,32,32))\n",
        "  cnn(input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wr_AMfs13tCw",
        "colab_type": "text"
      },
      "source": [
        "## 3rd Influence: Optimizer\n",
        "\n",
        "https://arxiv.org/pdf/1506.01186.pdf cyclical lr -> implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgrkB_c53Y-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(cnn.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# CLR\n",
        "def cyclical_learning_rate(min_lr, max_lr, stepsize, mode='triangular'):\n",
        "  if mode == 'triangular':\n",
        "    scaler = lambda x: 1\n",
        "  if mode == 'triangular2':\n",
        "    scaler = lambda x: (1/2)**(x-1)\n",
        "\n",
        "  lr_scheduler = lambda iteration: min_lr + (max_lr - min_lr)*eval(iteration, stepsize)\n",
        "\n",
        "# What about exp? Shown not to yield significantly better results, more complex to implement so didn't\n",
        "\n",
        "  def eval(iteration, stepsize):\n",
        "    cycle = math.floor(1+(iteration/stepsize))\n",
        "    x = abs(iteration/stepsize - 2*cycle +1)\n",
        "    return max(0,(1-x))*scaler(cycle)\n",
        "\n",
        "  return lr_scheduler\n",
        "\n",
        "# Stepsize is good when = (Nbr iterations / epoch) * 2 ~ 10. We choose 2 multiplier.\n",
        "stepsize = len(train_sampler) / BATCH_SIZE * 2\n",
        "lambdaCLR = cyclical_learning_rate(LEARNING_RATE, LEARNING_RATE * 6, stepsize)\n",
        "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambdaCLR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifI71NXikDfc",
        "colab_type": "text"
      },
      "source": [
        "# ===========\n",
        "\n",
        "#### Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQcs6e4qAE02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def serializeObject(obj, fileName):\n",
        "    with open(fileName, 'wb') as fileHandler:\n",
        "        pickle.dump(obj, fileHandler, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def train_network(ann, train_loader, validation_loader,\n",
        "                  optimizer, scheduler, criterion,\n",
        "                  batch_size=2, lr=0.0001, epoch=2,\n",
        "                  download=False, root_directory='',\n",
        "                  record_every=20):\n",
        "    \n",
        "    training_loss = []\n",
        "    validation_loss = []  \n",
        "\n",
        "    validation_set_size = len(validation_loader.sampler)\n",
        "\n",
        "    for e in range(epoch):\n",
        "        \n",
        "        running_loss = 0.\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data\n",
        "            optimizer.zero_grad()\n",
        "            outputs = ann(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # Scheduler step as well!\n",
        "            scheduler.step()\n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            if i % record_every == (record_every - 1):\n",
        "                print('[%d, %5d] loss: %.3f' %\n",
        "                      (e + 1, i + 1, running_loss / record_every))\n",
        "                # Training loss\n",
        "                training_loss.append(running_loss / record_every)\n",
        "                running_loss = 0.0\n",
        "            \n",
        "                # Validation loss\n",
        "                running_validation_loss = 0\n",
        "                for indices, data in enumerate(validation_loader, 0):\n",
        "                    inputs, labels = data\n",
        "                    outputs = ann(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    running_validation_loss += loss.item()\n",
        "                validation_loss.append(running_validation_loss / (validation_set_size/batch_size))\n",
        "    \n",
        "    \n",
        "    if download:\n",
        "        dir_name = '{0}/training_recording_part3/bs{1},lr{2},epoch{3}'.format(root_directory, batch_size, lr, epoch)\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.makedirs(dir_name)\n",
        "        \n",
        "        # Save losses for eventual future use\n",
        "        serializeObject(training_loss, dir_name + '/training_loss.pickle')\n",
        "        serializeObject(validation_loss, dir_name + '/validation_loss.pickle')\n",
        "\n",
        "        # Save network weights for eventual future use\n",
        "        torch.save(ann.state_dict(), dir_name + '/network_weights.pickle')\n",
        "        \n",
        "        iterations = np.arange(len(training_loss))*record_every\n",
        "        plt.figure()\n",
        "        plt.title('Training and Validation Loss During Training')\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.ylabel('Loss Value')\n",
        "        plt.plot(iterations, training_loss, '-', color='royalblue')\n",
        "        plt.plot(iterations, validation_loss, '-', color='tomato')\n",
        "        plt.legend(['Training', 'Validation'])\n",
        "        plt.savefig(dir_name + '/e{0},lr{1},bs{2}.png'.format(epoch, lr, batch_size), bbox_inches='tight')\n",
        "\n",
        "        \n",
        "    \n",
        "    return ann"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSAjsg3hlVzn",
        "colab_type": "text"
      },
      "source": [
        "#### Eval"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVKLCfNtmtoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def eval_net(net, testloader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    \n",
        "    # Own\n",
        "    accuracy = 100 * correct / total\n",
        "    \n",
        "    print('Accuracy of the network on the 10000 test images: %d %%' % (accuracy))\n",
        "    return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9h1bq1Solo-A",
        "colab_type": "text"
      },
      "source": [
        "#### Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_td11kPlm77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752
        },
        "outputId": "1c06c9b0-0032-4e33-a125-2c456e8a9d80"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(trainset,\n",
        "                                           batch_size=BATCH_SIZE,\n",
        "                                           num_workers=2,\n",
        "                                           sampler=train_sampler\n",
        "                                          )\n",
        "validation_loader = torch.utils.data.DataLoader(trainset,\n",
        "                                                batch_size=BATCH_SIZE,\n",
        "                                                num_workers=2,\n",
        "                                                sampler=validation_sampler\n",
        "                                               )\n",
        "\n",
        "cnn = train_network(cnn, train_loader, validation_loader,\n",
        "                    optimizer, scheduler, criterion,\n",
        "                    batch_size=BATCH_SIZE, lr=LEARNING_RATE, epoch=EPOCHS,\n",
        "                    record_every=RECORD_EVERY)\n",
        "\n",
        "accuracy = eval_net(cnn, testloader)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1,  2000] loss: 2.305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-125da2ab07d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     record_every=RECORD_EVERY)\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-89-5a519f153095>\u001b[0m in \u001b[0;36mtrain_network\u001b[0;34m(ann, train_loader, validation_loader, optimizer, scheduler, criterion, batch_size, lr, epoch, download, root_directory, record_every)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mann\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Scheduler step as well!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "BrokenPipeError: [Errno 32] Broken pipe\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 240, in _feed\n",
            "    send_bytes(obj)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 200, in send_bytes\n",
            "    self._send_bytes(m[offset:offset + size])\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 404, in _send_bytes\n",
            "    self._send(header + buf)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/connection.py\", line 368, in _send\n",
            "    n = write(self._handle, buf)\n",
            "BrokenPipeError: [Errno 32] Broken pipe\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_i0k7Wjnch0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}